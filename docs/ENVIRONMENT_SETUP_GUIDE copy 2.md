# Environment Setup Guide

## üéØ Overview

This guide explains the environment configuration for your e-commerce microservices platform, including fixes for Redis, Kafka, and MongoDB connection issues.

---

## üîß What Was Fixed

### **Issues Resolved:**

1. ‚úÖ **Redis Connection Error** - `ECONNREFUSED ::1:6379`
   - **Problem**: Service trying to connect to IPv6 localhost (::1) instead of IPv4
   - **Solution**: Properly configured REDIS_HOST with IPv4 addresses and separate Redis DB indexes

2. ‚úÖ **Kafka Connection Error** - `The group coordinator is not available`
   - **Problem**: Services trying to connect to wrong Kafka broker address
   - **Solution**: Use `kafka:29092` for Docker, `localhost:9092` for local development

3. ‚úÖ **Order Service Kafka Error** - `getaddrinfo EAI_AGAIN kafka1`
   - **Problem**: Order service configured with non-existent Kafka brokers (kafka1, kafka2, kafka3)
   - **Solution**: Updated to use correct single Kafka broker

4. ‚úÖ **Environment Inconsistency**
   - **Problem**: Mixed MongoDB Atlas and local MongoDB URIs
   - **Solution**: Separate `.env.local` and `.env.production` files

---

## üìÅ Environment File Structure

Each service now has **TWO** environment files:

```
services/
‚îú‚îÄ‚îÄ auth/
‚îÇ   ‚îú‚îÄ‚îÄ .env                 ‚Üê Active config (copied from .env.local for development)
‚îÇ   ‚îú‚îÄ‚îÄ .env.local           ‚Üê LOCAL development (localhost)
‚îÇ   ‚îî‚îÄ‚îÄ .env.production      ‚Üê PRODUCTION/Docker (container names)
‚îú‚îÄ‚îÄ product/
‚îÇ   ‚îú‚îÄ‚îÄ .env
‚îÇ   ‚îú‚îÄ‚îÄ .env.local
‚îÇ   ‚îî‚îÄ‚îÄ .env.production
‚îú‚îÄ‚îÄ user/
‚îÇ   ‚îú‚îÄ‚îÄ .env
‚îÇ   ‚îú‚îÄ‚îÄ .env.local
‚îÇ   ‚îî‚îÄ‚îÄ .env.production
‚îú‚îÄ‚îÄ inventory/
‚îÇ   ‚îú‚îÄ‚îÄ .env
‚îÇ   ‚îú‚îÄ‚îÄ .env.local
‚îÇ   ‚îî‚îÄ‚îÄ .env.production
‚îú‚îÄ‚îÄ order/
‚îÇ   ‚îú‚îÄ‚îÄ .env
‚îÇ   ‚îú‚îÄ‚îÄ .env.local
‚îÇ   ‚îî‚îÄ‚îÄ .env.production
‚îî‚îÄ‚îÄ gateway/
    ‚îú‚îÄ‚îÄ .env
    ‚îú‚îÄ‚îÄ .env.local
    ‚îî‚îÄ‚îÄ .env.production
```

---

## üåç Environment Configurations

### **Local Development (`.env.local`)**

Used when running services **outside Docker** (on your local machine):

```bash
NODE_ENV=development

# MongoDB - Use localhost
MONGO_URI=mongodb://localhost:27017/service-name

# Redis - Use localhost with unique DB index per service
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0  # Different for each service (0-4)

# Kafka - Use localhost
KAFKA_BROKER=localhost:9092
KAFKA_BROKERS=localhost:9092
```

**When to use**: Running individual services locally with `./start-dev.sh`

---

### **Production/Docker (`.env.production`)**

Used when running services **inside Docker containers**:

```bash
NODE_ENV=production

# MongoDB - Use Docker container name
MONGO_URI=mongodb://mongo:27017/service-name

# Redis - Use Docker container name with unique DB index
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0  # Different for each service (0-4)

# Kafka - Use Docker internal port
KAFKA_BROKER=kafka:29092
KAFKA_BROKERS=kafka:29092
```

**When to use**: Running with `docker-compose up` or `./start-enhanced.sh`

---

## üî¢ Redis Database Indexes

To prevent data conflicts, each service uses a **unique Redis database index**:

| Service | Redis DB Index | Purpose |
|---------|----------------|---------|
| **Auth** | 0 | Session tokens, auth codes |
| **Product** | 1 | Product cache |
| **User** | 2 | User data cache |
| **Inventory** | 3 | Stock levels cache |
| **Order** | 4 | Order status cache |

This allows all services to share one Redis instance without data collision.

---

## üì® Kafka Configuration

### **Docker Environment**
```bash
# Use internal Docker network port
KAFKA_BROKER=kafka:29092
KAFKA_BROKERS=kafka:29092
```

### **Local Development**
```bash
# Use host-accessible port
KAFKA_BROKER=localhost:9092
KAFKA_BROKERS=localhost:9092
```

### **Important Notes:**
- **Inside Docker**: Services use `kafka:29092` (internal Docker network)
- **From Host**: Your machine uses `localhost:9092` (exposed to host)
- **Never use**: Multiple brokers (kafka1, kafka2, kafka3) - we only have one broker

---

## üóÑÔ∏è MongoDB Configuration

### **Docker Environment**
```bash
MONGO_URI=mongodb://mongo:27017/service-name
```

### **Local Development**
```bash
# Option 1: Local MongoDB (recommended for dev)
MONGO_URI=mongodb://localhost:27017/service-name

# Option 2: MongoDB Atlas (cloud)
MONGO_URI=mongodb+srv://user:pass@cluster.mongodb.net/service-name
```

---

## üöÄ How to Use

### **Method 1: Docker (Full Stack)**

```bash
# Start everything with Docker Compose
./start-enhanced.sh
```

**What happens:**
- Docker Compose uses `.env.production` files
- Services connect via Docker network (redis, mongo, kafka:29092)
- No manual env setup needed

---

### **Method 2: Local Development (Individual Services)**

```bash
# Step 1: Start infrastructure
./start-infrastructure.sh

# Step 2: Start service locally
cd services/auth
./start-dev.sh
```

**What happens:**
- Script copies `.env.local` to `.env` if needed
- Service reads `.env` file
- Connects to `localhost:27017`, `localhost:6379`, `localhost:9092`
- Hot reload enabled for fast development

---

### **Method 3: Hybrid (Some Docker, Some Local)**

```bash
# Start infrastructure + some services in Docker
docker-compose up -d mongo redis kafka auth-service user-service

# Run product service locally for development
cd services/product
./start-dev.sh
```

**Benefits:**
- Fast hot reload for service you're developing
- Other services running in background
- Best of both worlds

---

## üîç Environment Variables Reference

### **Common Variables (All Services)**

```bash
NODE_ENV=development|production        # Environment mode
PORT=3000                             # Service port
SERVICE_NAME=service-name             # Service identifier
```

### **Database Variables**

```bash
MONGO_URI=mongodb://host:27017/dbname # MongoDB connection
REDIS_HOST=localhost|redis            # Redis host
REDIS_PORT=6379                       # Redis port
REDIS_DB=0                            # Redis database index (0-15)
REDIS_PASSWORD=                       # Redis password (if any)
```

### **Kafka Variables**

```bash
KAFKA_BROKER=localhost:9092           # Kafka broker (singular)
KAFKA_BROKERS=localhost:9092          # Kafka brokers (for multiple)
KAFKA_CLIENT_ID=service-name          # Unique client ID
KAFKA_GROUP_ID=service-name-group     # Consumer group ID
```

### **Auth Service Specific**

```bash
JWT_ISS=http://localhost:4000         # JWT issuer URL
ACCESS_TOKEN_EXPIRES_IN=15m           # Access token expiry
REFRESH_TOKEN_EXPIRES_IN=30d          # Refresh token expiry
JWT_ALG=RS256                         # JWT algorithm
```

### **Gateway Specific**

```bash
GATEWAY_PORT=3008                     # Gateway port
AUTH_SERVICE_URL=http://localhost:4000        # Auth service URL
USER_SERVICE_URL=http://localhost:3001        # User service URL
PRODUCT_SERVICE_URL=http://localhost:3002     # Product service URL
INVENTORY_SERVICE_URL=http://localhost:3003   # Inventory service URL
ORDER_SERVICE_URL=http://localhost:5003       # Order service URL
```

---

## üîê Production Secrets

For production, **NEVER commit secrets** to git. Use one of these approaches:

### **Option 1: Environment Variables**
```bash
export JWT_SECRET="your-super-secret-key"
export MONGO_URI="mongodb+srv://user:password@cluster.mongodb.net/dbname"
```

### **Option 2: Docker Secrets**
```yaml
# docker-compose.yml
services:
  auth-service:
    secrets:
      - jwt_secret
      - mongo_uri

secrets:
  jwt_secret:
    external: true
  mongo_uri:
    external: true
```

### **Option 3: AWS Secrets Manager / Vault**
- Store secrets in AWS Secrets Manager
- Retrieve at runtime
- Rotate automatically

---

## üõ†Ô∏è Troubleshooting

### **Problem: Redis Connection Refused**

```
Error: connect ECONNREFUSED ::1:6379
```

**Solution:**
1. Check Redis is running:
   ```bash
   docker ps | grep redis
   # or
   redis-cli ping
   ```

2. Verify REDIS_HOST in your `.env`:
   ```bash
   # For local development
   REDIS_HOST=localhost

   # For Docker
   REDIS_HOST=redis
   ```

3. Ensure correct Redis DB index is set (0-4)

---

### **Problem: Kafka Group Coordinator Not Available**

```
ERROR [Connection] Response GroupCoordinator(key: 10, version: 2)
{"error":"The group coordinator is not available"}
```

**Solution:**
1. Wait for Kafka to be fully healthy (takes 30-60 seconds):
   ```bash
   docker-compose logs kafka | grep "started"
   ```

2. Verify KAFKA_BROKER setting:
   ```bash
   # For local development
   KAFKA_BROKER=localhost:9092

   # For Docker
   KAFKA_BROKER=kafka:29092
   ```

3. Check Kafka is accessible:
   ```bash
   # From host
   nc -zv localhost 9092

   # From container
   docker exec ecom-kafka kafka-broker-api-versions --bootstrap-server kafka:29092
   ```

---

### **Problem: MongoDB Connection Failed**

```
Error: connect ECONNREFUSED 127.0.0.1:27017
```

**Solution:**
1. Check MongoDB is running:
   ```bash
   docker ps | grep mongo
   # or
   mongosh --eval "db.adminCommand('ping')"
   ```

2. Verify MONGO_URI in `.env`:
   ```bash
   # For local development
   MONGO_URI=mongodb://localhost:27017/service-name

   # For Docker
   MONGO_URI=mongodb://mongo:27017/service-name
   ```

---

### **Problem: Service Can't Find Kafka1, Kafka2, Kafka3**

```
Error: getaddrinfo EAI_AGAIN kafka1
```

**Solution:**
This is fixed! Update your `.env` files:

**Before (WRONG):**
```bash
KAFKA_BROKERS=kafka1:9092,kafka2:9092,kafka3:9092
```

**After (CORRECT):**
```bash
KAFKA_BROKERS=kafka:29092
```

We only have ONE Kafka broker in docker-compose.

---

## üéØ Quick Reference

### **Local Development Checklist**

```bash
# 1. Ensure infrastructure is running
./start-infrastructure.sh

# 2. Check services are accessible
nc -zv localhost 27017  # MongoDB
nc -zv localhost 6379   # Redis
nc -zv localhost 9092   # Kafka

# 3. Start your service
cd services/auth
./start-dev.sh
```

### **Docker Deployment Checklist**

```bash
# 1. Ensure .env.production files exist
ls services/*/.env.production

# 2. Clean previous containers
./stop-enhanced.sh -v

# 3. Start everything
./start-enhanced.sh

# 4. Check status
./status.sh
```

### **Environment File Checklist**

For each service, ensure:
- ‚úÖ `.env.local` exists (for local dev)
- ‚úÖ `.env.production` exists (for Docker)
- ‚úÖ `.env` is a copy of `.env.local` (active config for local dev)
- ‚úÖ Redis DB index is unique (0-4)
- ‚úÖ Kafka broker address is correct
- ‚úÖ MongoDB URI matches environment

---

## üìä Environment Variables Summary

| Variable | Local Value | Production Value |
|----------|-------------|------------------|
| MONGO_URI | mongodb://localhost:27017 | mongodb://mongo:27017 |
| REDIS_HOST | localhost | redis |
| REDIS_PORT | 6379 | 6379 |
| REDIS_DB | 0-4 (unique per service) | 0-4 (unique per service) |
| KAFKA_BROKER | localhost:9092 | kafka:29092 |
| NODE_ENV | development | production |

---

## ‚úÖ Verification

After setup, verify everything works:

```bash
# 1. Start infrastructure
./start-infrastructure.sh

# 2. Test MongoDB
mongosh --eval "db.adminCommand('ping')"

# 3. Test Redis
redis-cli ping

# 4. Test Kafka
docker-compose logs kafka | grep "started"

# 5. Start a service
cd services/auth
./start-dev.sh

# Should see:
# ‚úì MongoDB is running
# ‚úì Redis is running
# ‚úì Kafka is running
# Starting Auth Service on http://localhost:4000
```

---

## üéâ Summary

**What's Now Working:**

‚úÖ **Redis connections** - Each service uses unique Redis DB index (0-4)
‚úÖ **Kafka connections** - Correct broker addresses for Docker and local
‚úÖ **MongoDB connections** - Separate configs for local and production
‚úÖ **Environment separation** - `.env.local` and `.env.production` files
‚úÖ **Independent services** - Each service can run alone or with Docker
‚úÖ **Deployment ready** - Docker Compose uses production configs

**No More Errors:**
- ‚ùå `ECONNREFUSED ::1:6379`
- ‚ùå `group coordinator is not available`
- ‚ùå `getaddrinfo EAI_AGAIN kafka1`

**Your platform is now production-ready!** üöÄ
